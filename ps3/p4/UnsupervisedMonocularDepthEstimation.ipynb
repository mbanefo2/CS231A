{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3959e5e6",
      "metadata": {
        "id": "3959e5e6"
      },
      "source": [
        "# CS231a PSET 3 Problem 4: Unsupervised Monocular Depth Estimation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This the notebook you can use to complete problem 4. It's not necessary, but it may be helpful so that you don't need to install new python packges. To get going, let's get access to the data and code as in the prior problems. You can also skip this step and just upload the files directly using the files tab, though any changes you make will be gone if you close the tab or the colab runtime ends."
      ],
      "metadata": {
        "id": "4EwozYQ6ehtv"
      },
      "id": "4EwozYQ6ehtv"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Enter the foldername in your Drive where you have saved the unzipped\n",
        "# '.py' files from the p4 folder\n",
        "# e.g. 'cs231a/pset3/p4'\n",
        "FOLDERNAME = 'cs231a/pset3/p4'\n",
        "\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "%cd drive/My\\ Drive\n",
        "%cd $FOLDERNAME"
      ],
      "metadata": {
        "id": "Q5CXWpZ_elB2"
      },
      "id": "Q5CXWpZ_elB2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, you should be able to run the following with no problem."
      ],
      "metadata": {
        "id": "KBsCnuOpjqI8"
      },
      "id": "KBsCnuOpjqI8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45576560",
      "metadata": {
        "id": "45576560"
      },
      "outputs": [],
      "source": [
        "# Dataloading\n",
        "\n",
        "import importlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as tvutils\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import problems\n",
        "\n",
        "data = np.load('data.npz')\n",
        "disparities = data['disparities']\n",
        "left_images = data['left_image']\n",
        "right_images = data['right_image']\n",
        "left_image_t = torch.from_numpy(left_images[0])\n",
        "right_image_t = torch.from_numpy(right_images[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3e4c667",
      "metadata": {
        "id": "e3e4c667"
      },
      "source": [
        "## a. Horizontal flip data augmentation\n",
        "Before we get started, we would like you to implement a data augmentation function for stereo images that randomly flips the given image horizontally. In neural networks, data augmentation takes a crucial role in better generalization of the problem. One of the most common data augmentation when using 2D images as input is to randomly flip the image horizontally. One interesting difference in our problem setup is that we take a pair of rectified stereo images as input. In order to maintain the stereo relationship after the horizontal flip, it requires a special attention. Please fill in the code in StereoRandomFlip to implement the data augmentation function."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6048f37a",
      "metadata": {
        "id": "6048f37a"
      },
      "source": [
        "Following is a visualization of a sample of input stereo images. Please fill in the function that correctly flip the stereo image for data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "791d36d6",
      "metadata": {
        "id": "791d36d6"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(1, 2, dpi=200)\n",
        "ax[0].imshow(np.transpose(left_image_t, (1, 2, 0)))\n",
        "ax[0].title.set_text('left')\n",
        "ax[1].imshow(np.transpose(right_image_t, (1, 2, 0)))\n",
        "ax[1].title.set_text('right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b8bc178",
      "metadata": {
        "id": "8b8bc178"
      },
      "outputs": [],
      "source": [
        "importlib.reload(problems)\n",
        "\n",
        "transform_flip = problems.StereoRandomFlip()\n",
        "flipped_left_t, flipped_right_t = transform_flip._flip(left_image_t, right_image_t)\n",
        "f, ax = plt.subplots(1, 2, dpi=200)\n",
        "ax[0].imshow(np.transpose(flipped_left_t, (1, 2, 0)))\n",
        "ax[0].title.set_text('flipped left')\n",
        "ax[1].imshow(np.transpose(flipped_right_t, (1, 2, 0)))\n",
        "ax[1].title.set_text('flipped right')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cc4b019",
      "metadata": {
        "id": "6cc4b019"
      },
      "source": [
        "## b. Implement bilinear sampler\n",
        "\n",
        "Next, implement a function bilinear_sampler which shifts the given horizontally given the disparity. The core idea of unsupervised monocular depth estimation is that we can generate left image from right and vice versa by sampling rectified images horizontally using the disparity. We will ask you to implement a function that simply samples image with horizontal displacement as given by the input disparity. Fill in the bilinear_sampler method at p5/problems.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ca09da9",
      "metadata": {
        "id": "5ca09da9"
      },
      "outputs": [],
      "source": [
        "importlib.reload(problems)\n",
        "\n",
        "img_left = torch.from_numpy(left_images)\n",
        "img_right = torch.from_numpy(right_images)\n",
        "\n",
        "shift_left = torch.ones_like(img_left) * 0.5\n",
        "shift_right = torch.ones_like(img_left) * -0.5\n",
        "\n",
        "img_shift_left_half = problems.bilinear_sampler(img_left, shift_left)\n",
        "img_shift_right_half = problems.bilinear_sampler(img_left, shift_right)\n",
        "\n",
        "f, ax = plt.subplots(1, 3, dpi=200)\n",
        "ax[0].imshow(np.transpose(img_left[0], (1, 2, 0)))\n",
        "ax[0].title.set_text('original image')\n",
        "ax[1].imshow(np.transpose(img_shift_left_half[0], (1, 2, 0)))\n",
        "ax[1].title.set_text('shift to left by half')\n",
        "ax[2].imshow(np.transpose(img_shift_right_half[0], (1, 2, 0)))\n",
        "ax[2].title.set_text('shift to right by half')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58b0023c",
      "metadata": {
        "id": "58b0023c"
      },
      "source": [
        "## c. Implement left/right image generator.\n",
        "\n",
        "Finally, implement functions generate_image_right and generate_image_left which generates right view of the image from left image using the disparity and vice versa. This will be a simple one-liner that applies bilinear_sampler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07fc567f",
      "metadata": {
        "id": "07fc567f"
      },
      "outputs": [],
      "source": [
        "importlib.reload(problems)\n",
        "\n",
        "img_left = torch.from_numpy(left_images)\n",
        "img_right = torch.from_numpy(right_images)\n",
        "disp_l = torch.from_numpy(disparities[0, 0]).unsqueeze(0).unsqueeze(0)\n",
        "disp_r = torch.from_numpy(disparities[0, 1]).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "img_left_est = problems.generate_image_left(img_right, disp_l)\n",
        "img_right_est = problems.generate_image_right(img_left, disp_r)\n",
        "disp_left_est = problems.generate_image_left(disp_r, disp_l)\n",
        "disp_right_est = problems.generate_image_right(disp_l, disp_r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c5912dc",
      "metadata": {
        "id": "3c5912dc"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(1, 2, dpi=200)\n",
        "ax[0].imshow(np.transpose(img_left[0], (1, 2, 0)))\n",
        "ax[0].title.set_text('left image')\n",
        "ax[0].title.set_fontsize(9)\n",
        "ax[1].imshow(np.transpose(img_left_est[0], (1, 2, 0)))\n",
        "ax[1].title.set_text('synthesized left image')\n",
        "ax[1].title.set_fontsize(9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68aa7d76",
      "metadata": {
        "id": "68aa7d76"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(1, 2, dpi=200)\n",
        "ax[0].imshow(np.transpose(img_right[0], (1, 2, 0)))\n",
        "ax[0].title.set_text('right image')\n",
        "ax[0].title.set_fontsize(9)\n",
        "ax[1].imshow(np.transpose(img_right_est[0], (1, 2, 0)))\n",
        "ax[1].title.set_text('synthesized right image')\n",
        "ax[1].title.set_fontsize(9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5a036b3",
      "metadata": {
        "id": "f5a036b3"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(1, 2, dpi=200)\n",
        "ax[0].imshow(disparities[0, 0], cmap='plasma')\n",
        "ax[0].title.set_text('left disp')\n",
        "ax[0].title.set_fontsize(9)\n",
        "ax[1].imshow(disp_left_est[0, 0], cmap='plasma')\n",
        "ax[1].title.set_text('synthesized left disp')\n",
        "ax[1].title.set_fontsize(9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a098811",
      "metadata": {
        "id": "2a098811"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(1, 2, dpi=200)\n",
        "ax[0].imshow(disparities[0, 1], cmap='plasma')\n",
        "ax[0].title.set_text('right disp')\n",
        "ax[0].title.set_fontsize(9)\n",
        "ax[1].imshow(disp_right_est[0, 0], cmap='plasma')\n",
        "ax[1].title.set_text('synthesized right disp')\n",
        "ax[1].title.set_fontsize(9)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "That's it, you are done! Remember to submit your code by .py files to the autograder."
      ],
      "metadata": {
        "id": "YtDqtpIvSwlT"
      },
      "id": "YtDqtpIvSwlT"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs231a",
      "language": "python",
      "name": "cs231a"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}